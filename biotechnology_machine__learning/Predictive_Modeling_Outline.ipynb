{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Predictive Modeling Outline"
      ],
      "metadata": {
        "id": "O36fy7HH-4EY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Data\n",
        "- electronic health data - Longitudinal EHR, multimodality, rich data types\n",
        "        (hospital visits: symptom, diagnosis, lab tests, imaging )\n",
        "- medical claims - medicare and private insurance, inpatient/outpatient\n",
        "        (member info, diagnosis, procedure, medication, financial info)\n",
        "- medical literature - PubMed\n",
        "- notes - admission, progress, radiology, physician, summary\n",
        "        progress notes (SOAP), Subjective, Objective, Assessment, Plan\n",
        "- medical ontology - MESH, ATC, CPT, RxNorm\n",
        "- imaging data - Imaging (X-ray, tomography CT, MRI, PET-CT)\n",
        "        storage size per image(Pet -9gb, CT-36gb, MRI-300gn), estimated in pt/tb\n",
        "- clinical trial - CTMS, Protocols, FDA adverse event database\n",
        "- drug discovery - DrugBank and Chemical database for Drug discovery\n",
        "'''"
      ],
      "metadata": {
        "id": "AdIFoS8RiznQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Supervised Learning\n",
        "Predictive modeling\n",
        "Gradient and Stochastic Gradient Descent\n",
        "Predictive modeling pipeline:\n",
        "  Prediction target -> Cohort construction -> Feature construction\n",
        "  -> Feature selection -> Predictive modeling -> Performance evaluation\n",
        "\n",
        "Cohort construction: dataset for the model, prospective and retrospective studies\n",
        "Feature construction: Observation window -> index -> prediction -> diagnosis (date)\n",
        "Feature selection: diagnosis,symptoms, labs,vitals, medications\n",
        "Predictive Modeling: Classification Target(y) = f(x) +Error(e)\n",
        "  Logistic Reg(Generalized Additive), SVM, Decision trees, Random Forest, DL\n",
        "CV( leave-1-out CV,k-fold CV, randomized CV)\n",
        "'''"
      ],
      "metadata": {
        "id": "WH2SgRt5m5OD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Hospital dataset\n",
        "Characteristics of a full dataset\n",
        "- total admissions,individuals, procedures, diagnoses, ICD-10 am codes,\n",
        "number of admissions in the past,\n",
        "variables used in prediction such as age, mean, white/asian, length of stay,\n",
        "\n",
        "Cohort with admissions and each feature for admission, multi category diagnosis\n",
        "For each diagnosis COPD, Diabetes,heart failure, AMI, based on the size and\n",
        "readmission rate, compare the accuracy/AUC between models\n",
        "'''"
      ],
      "metadata": {
        "id": "DIZUc81opaRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' use datasets from Kaggle  '''"
      ],
      "metadata": {
        "id": "ZqL4MZCnq3C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Embedding, Word2Vec\n",
        "\n",
        "Embedding methods: Word2Vec, t-SNE\n",
        "EHR: Med2Vec, Mime\n",
        "\n",
        "Word2Vec, NN to produce vector output\n",
        "Input (medical corpus) -> NN -> category(diabetes, COPD, covid-19)\n",
        "\n",
        "One hot encoding vector for each word\n",
        "covide-19 |0|0|...|1|0\n",
        "Sequence of one-hot vectors for each person\n",
        "___covid-19___diabetes___COPD\n",
        "Word2Vec, Skipgram\n",
        "maxSum(all_pairs_c,t(p(c|t)))\n",
        "p(c|t)) = exp(v_c^T v_t)/Sum_all_words(w)exp(v_w^T v_t) ~ expensive\n",
        "speed up the sampling for Word2Vec\n",
        "arg_max_theta(Product(p(D=1|c,w; theta))) pos samples *\n",
        "      arg_max(theta)(Product(p(D=0|c,w; theta))) neg samples\n",
        "arg_max_theta(Sum(log(1/(1 +e^(-vc*v_w))))) +\n",
        "      arg_max_theta(Sum(log(1 - 1/(1 +e^(-vc*v_w)))))\n",
        "compute representations as the sum of medical embeddings, the output of Word2Vec\n",
        "\n",
        "Med2Vec is multi-layer representation for EHR\n",
        "'''"
      ],
      "metadata": {
        "id": "qVkw4RwFq-0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Visualization of High Dimensional data\n",
        "\n",
        "PCS to preserve pairwise distance\n",
        "t-SNE to preserve local neighborhoods (joint distribution with Gaussian kernels\n",
        "normalizaed by all pairs), and with output distribution the t-distribution,with\n",
        "1 degree freedom\n",
        "'''"
      ],
      "metadata": {
        "id": "14hZ-olXvvNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Autoencoders\n",
        "\n",
        "Sparse Autoencoder\n",
        "Denoising Autoencoders\n",
        "Stacked Autoencoders layer-wise pretraining\n",
        "Usecase: Computational Phenotype\n",
        "'''"
      ],
      "metadata": {
        "id": "_MW5Af7MyEZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Graph Neural Networks (GNN) '''"
      ],
      "metadata": {
        "id": "rJleCEhr02mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Generative Models\n",
        "\n",
        "Generative Adversarial NN (GAN) - Synthetic data\n",
        "Variational Autoencoder (VAE) - Molecule generation\n",
        "'''"
      ],
      "metadata": {
        "id": "LXT_SsqR1Gr8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}