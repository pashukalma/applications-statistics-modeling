{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Variational Autoencoder for Molecule generation"
      ],
      "metadata": {
        "id": "2wJ81D5rcRTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two main approaches for molecule generation\n",
        "- Automatic chemical design using data-driven continuous representation: This approach explores open-ended spaces of chemical compounds. The method is described in https://arxiv.org/abs/1610.02415.\n",
        "- Variational Autoencoder for molecule generation in drug discovery (MolGAN): This is a more implicit model for small molecule design, detailed in https://arxiv.org/abs/1805.11973."
      ],
      "metadata": {
        "id": "4TARRmA9RX5H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data-Driven Continuous Representation Approach\n",
        "\n",
        "In the first approach, an encoder converts a string representation of a molecule into a continuous vector. A decoder then converts this vector back into a discrete molecule representation (string). A predictor estimates properties from the latent vector of the molecule. The continuous representation allows for gradient optimization and search for functional compounds.\n",
        "\n",
        "Process:\n",
        "\n",
        "A discrete molecule representation (SMILES string) is converted into a vector for use in the latent space. Given a point in the latent space, the decoder produces a SMILES string. A multilayer perceptron estimates the target properties associated with each molecule. Gradient optimization is performed continuously in the latent space to find new latent representations that match specific desired properties. The new latent representations are then decoded into SMILES strings."
      ],
      "metadata": {
        "id": "0uSgsCBKS-TQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "graph LR\n",
        "    A[SMILES] --> B(Encoder);\n",
        "    B --> C[Latent Space];\n",
        "    C --> D(Decoder);\n",
        "    D --> E[SMILES];\n",
        "    B --> F{VAE jointly trained on properties};\n",
        "    D --> F;\n",
        "    F --> C;\n",
        "\n",
        "+--------+   -->   +---------+ ---->   +-------------------------------------+\n",
        "| SMILES | ---->   | Encoder | ---->   | VAE (Jointly Trained on Properties) |\n",
        "+--------+         +---------+         +-------------------------------------+\n",
        "\n",
        "            --->  +-------------+ --->  +---------+   --->  +---------------+\n",
        "            --->  | Latent Space| --->  | Decoder |   --->  | SMILES (Output)|\n",
        "                  +-------------+       +---------+         +---------------+\n",
        "\n",
        "Smiles representation\n",
        "We traverse themolecular graph in DFS manner with smallest labels at each point\n",
        "'''\n",
        "Chem.MolFromSmiles('COc(c1)cccc1C#N')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "xYhrmUNS-1Ko",
        "outputId": "9062b423-f8c6-47ee-83dc-2f466e79f733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<rdkit.Chem.rdchem.Mol at 0x7f0e9c7e6260>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Representations Learning\n",
        "Molecule in graph representation -> SMILES        SMILES Input\n",
        "                                                        |\n",
        "One hot encoding              - vectors input     Encoder NN (RNN)\n",
        "    Br C c 1 c [ n H ] n c 1                            |\n",
        "Br  1. 0 0 0 0 0 0 0 0 0 0 0                      Latent Space\n",
        "C   0. 1 0 0 0 0 0 0 0 0 0 0                      - Continuous molecu;ar --> y\n",
        "H   0. 0 0 0 0 0 0 1 0 0 0 0                      representation          prop.\n",
        "c   0. 0 1 0 1 0 0 0 0 0 1 0                            |                 pred\n",
        "n   ....      ....      ....                      Decoder NN\n",
        "Seq2Seq model with RNN to encode SMILES                 |\n",
        "VAE generates the new SMILES                      SMILES Output\n",
        "property prediction network added                       |\n",
        "'''\n",
        "Chem.MolFromSmiles('BrCc1c[nH]nc1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "0iImVg1Sl50O",
        "outputId": "586345b5-9968-4d12-e7fa-37de38909556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<rdkit.Chem.rdchem.Mol at 0x7f0e9c7e63b0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Components and Data\n",
        "\n",
        "RDKit: This machine learning toolkit transforms SMILES strings into molecules.\n",
        "\n",
        "SMILES: Used for string representation and as a data structure. Encoding serves as a data structure for molecules, facilitating search and algorithms for visualization or property computation.\n",
        "\n",
        "Datasets: QM9 and ZINC datasets are used. They come in SMILES format and include properties used for property analysis and drug-likeness assessment.\n",
        "\n",
        "Encoder: Utilizes a graph data structure and processes the graph's adjacency matrix and feature matrix via graph convolution layers for non-linearly transformed neighborhood aggregations.\n",
        "\n",
        "Decoder: Takes the latent space representation as input to predict the graph adjacency matrix and feature matrix of the corresponding molecules."
      ],
      "metadata": {
        "id": "zadn44SUS2Ks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation adapted from moleculeAI generation with VAE"
      ],
      "metadata": {
        "id": "ry28EloOMmEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Installations\n",
        "PyTorch and Rdkit are industry standards for use in molecular data '''"
      ],
      "metadata": {
        "id": "9ML-28_XUokz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torch rdkit\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, Descriptors\n",
        "from typing import Tuple, List, Dict"
      ],
      "metadata": {
        "id": "RCOVE0aIGKsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from __future__ import print_function"
      ],
      "metadata": {
        "id": "XkbQn5r1GKvz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' QM9 dataset as the standard benchmark '''\n",
        "!wget \"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/qm9.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okhJxKuCGKzz",
        "outputId": "8b24f44c-adcc-4915-e176-0bf6efe2d675"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-03 20:28:27--  https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/qm9.csv\n",
            "Resolving deepchemdata.s3-us-west-1.amazonaws.com (deepchemdata.s3-us-west-1.amazonaws.com)... 52.219.193.178, 3.5.161.183, 3.5.160.24, ...\n",
            "Connecting to deepchemdata.s3-us-west-1.amazonaws.com (deepchemdata.s3-us-west-1.amazonaws.com)|52.219.193.178|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29856825 (28M) [text/csv]\n",
            "Saving to: ‘qm9.csv.1’\n",
            "\n",
            "qm9.csv.1           100%[===================>]  28.47M  22.9MB/s    in 1.2s    \n",
            "\n",
            "2025-03-03 20:28:29 (22.9 MB/s) - ‘qm9.csv.1’ saved [29856825/29856825]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('qm9.csv')\n",
        "smiles_list = df['smiles'].tolist()\n",
        "print(f\"Extracted {len(smiles_list)} SMILES strings from the dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOAq1T_aGLDA",
        "outputId": "a863d32b-be50-4b89-af64-982ba0c1b6f5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 133885 SMILES strings from the dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(smiles_list[:15])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VA6kBELWxy-",
        "outputId": "18741fef-c359-470b-dc6c-43bf89847e96"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['C', 'N', 'O', 'C#C', 'C#N', 'C=O', 'CC', 'CO', 'CC#C', 'CC#N', 'CC=O', 'C(=O)N', 'CCC', 'CCO', 'COC']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smiles_list[20:25]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur3RFo9cXSsy",
        "outputId": "369496a5-d336-45cb-bcb8-0734553d7114"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CC(C)C', 'CC(C)O', 'C#CC#C', 'C#CC#N', 'C(#N)C#N']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' create the vocabulary for SMILES strings to process them as tokens '''\n",
        "from typing import List, Dict\n",
        "def create_vocabulary(smiles_list: List[str]) -> Dict[str, int]:\n",
        "    vocab = {'<': 0, '>': 1}  # Start and end tokens\n",
        "    for smiles in smiles_list:\n",
        "        for char in smiles:\n",
        "            if char not in vocab:\n",
        "              vocab[char] = len(vocab)\n",
        "    return vocab\n",
        "vocab = create_vocabulary(smiles_list)"
      ],
      "metadata": {
        "id": "1yjQrGMrcSMO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' one-hot encoded tensors\n",
        "for index, char in enumerate(smiles_list[:10]):\n",
        "  encoded = torch.zeros(100, len(vocab))\n",
        "  encoded[index, vocab.get(char,0)] = 1\n",
        "encoded\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuLSYccIWwZX",
        "outputId": "5e0817a8-4b6a-47f5-8a00-3aeba0dc6094"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' create custom dataset\n",
        "'<', and '>' start and end tokens added to the encoding + one-hot-encoding '''\n",
        "class SMILESDataset(Dataset):\n",
        "  def __init__(self, smiles_list, vocab, max_length: int = 100):\n",
        "    self.smiles_list = smiles_list\n",
        "    self.vocab = vocab\n",
        "    self.vocab_size = len(vocab)\n",
        "    self.max_length = max_length\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return len(self.smiles_list)\n",
        "\n",
        "  def __getitem__(self, idx: int) -> torch.Tensor:\n",
        "    smiles = '<' + self.smiles_list[idx] + '>'\n",
        "    encoded = torch.zeros(self.max_length, self.vocab_size)\n",
        "    for i, c in enumerate(smiles[:self.max_length]):\n",
        "      encoded[i, self.vocab.get(c, 0)] = 1\n",
        "    return encoded\n",
        "\n",
        "def custom_collate(batch):\n",
        "    return torch.stack(batch)\n",
        "\n",
        "batch_size = 128\n",
        "dataset = SMILESDataset(smiles_list, vocab, max_length=100)\n",
        "dataloader_qm9 = DataLoader(\n",
        "    dataset, batch_size=batch_size, shuffle=True,\n",
        "    collate_fn=custom_collate,\n",
        "    num_workers=2, pin_memory=True)"
      ],
      "metadata": {
        "id": "91C4TecEWwdo"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' model architecture\n",
        "VAE: Encoder- Latent Space - Decoder\n",
        "use GRU layers for the encoder and decoder\n",
        "\n",
        "Smiles vocab -> hidden_dim GRUs -> latent_dim GRUs -> reconstruction\n",
        "fc_mu fully connected layer for mean of latent space\n",
        "fc_logvar fully connected layer for log variance of latent space\n",
        "fc_output fully connected layer for output of decoder (output probabilities)\n",
        "'''\n",
        "class VAE(nn.Module):\n",
        "  def __init__(self, vocab_size, hidden_dim, latent_dim):\n",
        "    super(VAE, self).__init__()\n",
        "    self.vocab_size = vocab_size\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.latent_dim = latent_dim\n",
        "    self.encoder = nn.GRU(vocab_size, hidden_dim, batch_first=True)\n",
        "    self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
        "    self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
        "    self.decoder = nn.GRU(vocab_size + latent_dim, hidden_dim, batch_first=True)\n",
        "    self.fc_output = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "  def encode(self, x):\n",
        "    _, h = self.encoder(x)\n",
        "    h = h.squeeze(0)\n",
        "    mu = self.fc_mu(h)\n",
        "    logvar = self.fc_logvar(h)\n",
        "    return mu, logvar\n",
        "\n",
        "  def reparameterize(self, mu, logvar):\n",
        "    std = torch.exp(0.5 * logvar)\n",
        "    eps = torch.randn_like(std)\n",
        "    return mu + eps * std\n",
        "\n",
        "  def decode(self, z, max_length):\n",
        "    batch_size = z.size(0)\n",
        "    h = torch.zeros(1, batch_size, self.hidden_dim).to(z.device)\n",
        "    x = torch.zeros(batch_size, 1, self.vocab_size).to(z.device)\n",
        "    outputs = []\n",
        "    for _ in range(max_length):\n",
        "      z_input = z.unsqueeze(1).repeat(1, 1, 1)\n",
        "      decoder_input = torch.cat([x, z_input], dim=2)\n",
        "      output, h = self.decoder(decoder_input, h)\n",
        "      output = self.fc_output(output)\n",
        "      outputs.append(output)\n",
        "      x = torch.softmax(output, dim=1)\n",
        "    return torch.cat(outputs, dim=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    mu, logvar = self.encode(x)\n",
        "    z = self.reparameterize(mu, logvar)\n",
        "    output = self.decode(z, x.size(1))\n",
        "    return output, mu, logvar"
      ],
      "metadata": {
        "id": "-3eN4iyvWwmu"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' train the model with a reconstruction loss crossentropy and KL divergence '''\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    binaryCrossEntropy = nn.functional.binary_cross_entropy_with_logits(\n",
        "                                          recon_x, x, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return binaryCrossEntropy + 0.1 * KLD\n",
        "\n",
        "''' Model initialization '''\n",
        "vocab_size = len(vocab)\n",
        "hidden_dim = 256\n",
        "latent_dim = 64\n",
        "model = VAE(vocab_size, hidden_dim, latent_dim)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                    optimizer, mode='min', factor=0.5, patience=5)\n",
        "use_amp = torch.cuda.is_available()\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itK95VCXWwpX",
        "outputId": "9ee6bd0c-d0cd-4586-f070-8983f06cd9c3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-ec3eecfac4e5>:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Training loop '''\n",
        "def train(model, num_epochs, dataloader):\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "      batch = batch.to(device, non_blocking=True)\n",
        "      optimizer.zero_grad(set_to_none=True)\n",
        "      # Use autocast only if CUDA is available\n",
        "      with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "        recon_batch, mu, logvar = model(batch)\n",
        "        loss = loss_function(recon_batch, batch, mu, logvar)\n",
        "      # Backward pass and optimization with gradient scaling if CUDA is available\n",
        "      if use_amp:\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "      else:\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "      avg_loss = total_loss / len(dataloader.dataset)\n",
        "      #print(f'Epoch {epoch+1}, Average Loss: {avg_loss:.4f}')\n",
        "      # update learning rate\n",
        "      scheduler.step(avg_loss)\n",
        "      # current learning rate\n",
        "      current_lr = optimizer.param_groups[0]['lr']\n",
        "      #print(f'Current learning rate: {current_lr:.6f}')\n",
        "\n",
        "  print(\"Training complete!\")\n",
        "train(model, num_epochs =20, dataloader=dataloader_qm9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpjOZ1CxKmMt",
        "outputId": "2d26d4cd-ebee-4fbc-c4c6-e1bb58765bb0"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "qm9.csv  qm9.csv.1  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' set the model in evaluation mode '''\n",
        "model.eval()\n",
        "''' invert vocabulary for decoding '''\n",
        "invert_vocab = {value: key for key, value in vocab.items()}\n",
        "''' generate new molecules using decoder '''\n",
        "generated_smiles = []\n",
        "''' disable gradient computation '''\n",
        "with torch.no_grad():\n",
        "  for i in range(10):\n",
        "    z = torch.randn(1, model.latent_dim).to(device)\n",
        "    x = torch.zeros(1, 1,model.vocab_size).to(device)\n",
        "    x[0, 0, vocab['<']] = 1\n",
        "    h = torch.zeros(1, 1, model.hidden_dim).to(device)\n",
        "    smiles = ''\n",
        "    for _ in range(100):\n",
        "      z_input = z.unsqueeze(1) #.repeat(1, 1, 1)\n",
        "      decoder_input = torch.cat([x, z_input], dim=2)\n",
        "      output, h = model.decoder(decoder_input, h)\n",
        "      output = model.fc_output(output)\n",
        "      probs = torch.softmax(output.squeeze(0), dim=-1)\n",
        "      next_char = torch.multinomial(probs, 1).item()\n",
        "      if invert_vocab[next_char] == '>':\n",
        "        break\n",
        "      smiles += invert_vocab[next_char]\n",
        "      x = torch.zeros(1, 1, model.vocab_size).to(device)\n",
        "      x[0, 0, next_char] = 1\n",
        "    generated_smiles.append(smiles)\n",
        "#len(generated_smiles)"
      ],
      "metadata": {
        "id": "VcdWSxDDGLHc"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, smiles in enumerate(generated_smiles):\n",
        "  print(f\"{index+1}: {smiles}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yYDqR7LoWsV",
        "outputId": "445e66f7-5229-4bc6-f193-6f8acd6e3dd9"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: #1[cn2]<=NO<(FN[)+3([)4H+#<#5H4[H2nN]+<#FN3NO=1)5[2c=F1<C3<HNNO2cN2oo4N-F)++]=-<H#+ON)<nCO]++N<4(\n",
            "2: C)N=4]n[131=1341([H3O#H#)\n",
            "3: nc4##oO3=3HncC]O\n",
            "4: O)FC2(n\n",
            "5: HN<=F[(5H[))+on)c(1([\n",
            "6: [5]N-N+)N5(NC+=n4\n",
            "7: 43n[FnnFOOH-c3H]<C)[5C<1]NcC11+NN3F513(OO#c-HC3cCnO(O#3Cn])-<\n",
            "8: C[C2#([\n",
            "9: n5(15([=5))1\n",
            "10: c-)+n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analysis = analyze_molecules(generated_smiles)"
      ],
      "metadata": {
        "id": "EuE1eGle3-lJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analysis['valid'], analysis['invalid'], analysis['unique'], analysis['corrected'], \\\n",
        "analysis['properties']"
      ],
      "metadata": {
        "id": "tH9UYcsZ7-MP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original implementation VAE\n",
        "\n",
        "The train the NN to predict properties in Latent Space\n",
        "\n",
        "link: https://pubs.acs.org/doi/10.1021/acscentsci.7b00572"
      ],
      "metadata": {
        "id": "lAXNeGtTGFLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MolecularVAE(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # encoder related blocks\n",
        "    self.conv_1 = nn.Conv1d(120, 9, kernel_size=9)\n",
        "    self.conv_2 = nn.Conv1d(9, 9, kernel_size=9)\n",
        "    self.conv_3 = nn.Conv1d(9, 10, kernel_size=11)\n",
        "    self.linear_0 = nn.Linear(70, 435)\n",
        "    self.linear_1 = nn.Linear(435, 292)\n",
        "    self.linear_2 = nn.Linear(435, 292)\n",
        "\n",
        "    # decoder related blocks\n",
        "    self.linear_3 = nn.Linear(292, 292)\n",
        "    self.gru = nn.GRU(292, 501, 3, batch_first=True)\n",
        "    self.linear_4 = nn.Linear(501, 33)\n",
        "\n",
        "    # activation function\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    def encode(self, x):\n",
        "      # forward pass through encoder\n",
        "      x = self.relu(self.conv_1(x))\n",
        "      x = self.relu(self.conv_2(x))\n",
        "      x = self.relu(self.conv_3(x))\n",
        "      x = x.view(x.size(0), -1)\n",
        "      x = F.selu(self.linear_0(x))\n",
        "      return self.linear_1(x), self.linear_2(x)\n",
        "\n",
        "    def sampling(self, z_mean, z_logvar):\n",
        "      # noise epsilon is added\n",
        "      epsilon = 1e-2 * torch.randn_like(z_logvar)\n",
        "      # return the latent vector, what the decoder uses to reconstruct the input)\n",
        "      return torch.exp(0.5 * z_logvar) * epsilon + z_mean\n",
        "\n",
        "    def decode(self, z):\n",
        "      # forward pass through decoder to go from latent vector back to a molecule\n",
        "      z = F.selu(self.linear_3(z))\n",
        "      z = z.view(z.size(0), 1, z.size(-1)).repeat(1, 120, 1)\n",
        "      output, hn = self.gru(z)\n",
        "      out_reshape = output.contiguous().view(-1, output.size(-1))\n",
        "      y0 = F.softmax(self.linear_4(out_reshape), dim=1)\n",
        "      y = y0.contiguous().view(output.size(0), -1, y0.size(-1))\n",
        "      return y\n",
        "\n",
        "    def forward(self, x):\n",
        "        # overall forward pass takes the input, passes it to the encoder/decoder\n",
        "        # encode input to get the mean and variance of the Gaussian is mapped to\n",
        "        z_mean, z_logvar = self.encode(x)\n",
        "        # get the latent vector taking the mean and variance and adding noise\n",
        "        z = self.sampling(z_mean, z_logvar)\n",
        "        # decode the latent vector, z, to reconstruct a molecule\n",
        "        return self.decode(z), z_mean, z_logvar\n",
        "\n",
        "def vae_loss(x_decoded_mean, x, z_mean, z_logvar):\n",
        "    '''\n",
        "    The loss function is a combination of 2 quantities:\n",
        "    1. \"reconstruction loss\" which measures how different the reconstructed\n",
        "        molecule is to the original. We would want them to be similar\n",
        "    2. \"Kullback–Leibler (KL) divergence\".\n",
        "        We are trying to approximate the distribution of the latent vector with\n",
        "        a Gaussian distribution. The KL divergence measure how \"off\" we are\n",
        "        reconstruction_loss = F.binary_cross_entropy(\n",
        "                                        x_decoded_mean, x, size_average=False)\n",
        "    '''\n",
        "    kl_loss = -0.5 * torch.sum(1 + z_logvar - z_mean.pow(2) - z_logvar.exp())\n",
        "    return reconstruction_loss + kl_loss"
      ],
      "metadata": {
        "id": "TEEydbyQcSXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6mWou4idcSau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tU8P0dzncSsO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}